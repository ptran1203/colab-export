{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FXGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptran1203/fxgan/blob/master/notebooks/fxgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvmfANcCG6cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive, output\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!rm -rf '/content/gan_project'\n",
        "!git clone https://github.com/ptran1203/gan_project\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "\n",
        "output.clear()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlyDd8NuYRtM",
        "colab_type": "text"
      },
      "source": [
        "## Create the link from this drive folder to your drive.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "https://drive.google.com/drive/folders/1RNJXceXkNatuAbNn-CKB8MrgaEHG5RpM?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csJrGduMHDsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c08d3d8-32e7-43b2-98d6-876fad99537f"
      },
      "source": [
        "cd gan_project"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gan_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h1G8Q0KgG4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0bc4f5e8-90b8-4970-ee9b-255ac919f5e4"
      },
      "source": [
        "\n",
        "# K.common.set_image_dim_ordering('tf')\n",
        "BASE_DIR = '/content/drive/My Drive/bagan'\n",
        "DS_DIR = '/content/drive/My Drive/bagan/dataset/chest_xray'\n",
        "DS_SAVE_DIR = '/content/drive/My Drive/bagan/dataset/save'\n",
        "gratio_mode = 'uniform'\n",
        "dratio_mode = 'uniform'\n",
        "\n",
        "from fxgan import *\n",
        "from batch_gen import *\n",
        "from utils import *\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "\n",
        "def create_dir_if_any(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "class FxGan(FXGAN):\n",
        "    attribute_loss_weight = 0\n",
        "    def interval_process(self, epoch):\n",
        "        if epoch % 400 == 0 and epoch > 0:\n",
        "            output.clear()\n",
        "\n",
        "    def build_features_from_d_model(self):\n",
        "        self.features_from_d_model = Model(\n",
        "            inputs = self.discriminator.inputs,\n",
        "            output = self.discriminator.layers[-2].get_output_at(-1),\n",
        "            name = 'Feature_matching'\n",
        "        )\n",
        "\n",
        "    def evaluate_g(self, test_x, test_y): return\n",
        "    def evaluate_d(self, test_x, test_y): return\n",
        "    def plot_feature_distr(self, bg, size=500): return\n",
        "\n",
        "class BatchGen(BatchGenerator):\n",
        "    to_train_classes = list(range(0, 80))\n",
        "    # to_train_classes = range(12)\n",
        "    to_test_classes = list(range(81, 102))\n",
        "\n",
        "\n",
        "is_test = 0\n",
        "## Test batch GEN\n",
        "if is_test:\n",
        "    bg = BatchGen(BatchGen.TRAIN, 64, 'multi_chest', 64)\n",
        "    labels = np.array([0, 0, 1, 1, 2, 2, 3 ,1])\n",
        "    samples = bg.ramdom_kshot_images(4, labels)\n",
        "    print(samples.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtIo2m__Za9s",
        "colab_type": "text"
      },
      "source": [
        "## **Train GAN**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVfcbmDU6ONX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stop when ever you want :))\n",
        "gan_epochs  = 400000\n",
        "# Discriminator learning rate\n",
        "adam_lr = 0.00003\n",
        "# Generator learning rate\n",
        "g_lr = 0.00001\n",
        "batch_size = 64\n",
        "# dataset_name should be \"flowers\", \"ch1est\", \"multi_chest\"\n",
        "# \"chest\" is binary classification, \"multi_chest\" using chest-xray14 dataset\n",
        "dataset_name = 'multi_chest'\n",
        "latent_size = 128\n",
        "# Use resnet architecture for Generator\n",
        "resnet = False\n",
        "# Use self-attention mechanism\n",
        "attention = False\n",
        "\n",
        "np.random.seed(0)\n",
        "# Image resoulution\n",
        "rst = 128\n",
        "# Number of images used to generate feature for Generator should be 2 - 5\n",
        "k_shot = 10\n",
        "\n",
        "# normal: sampling from normal distribution\n",
        "# code: sampling from latent code distribution (computed by classifier)\n",
        "sampling = 'normal'\n",
        "advance_losses = {\n",
        "    # 'l2_feat': 0.7,\n",
        "    'triplet': 0.7,\n",
        "    # 'fm_D': 0.3,\n",
        "    # 'triplet_D': 0.7,\n",
        "    # 'recon': 0.5,\n",
        "}\n",
        "\"\"\"\n",
        "batch: batch norm\n",
        "in: instance norm\n",
        "fn: feature norm\n",
        "D-fn: use feature norm for Discriminator\n",
        "\"\"\"\n",
        "norm = 'in-bn-fn'\n",
        "# Adversarial loss type\n",
        "loss_type = 'categorical'\n",
        "\n",
        "is_prune = False\n",
        "\n",
        "# prune = [1000, 3500] if is_prune else None\n",
        "prune = [1000] if dataset_name != 'flowers' else []\n",
        "\n",
        "res_dir =  '/content/drive/My Drive/GAN/result/model_{}_{}_v2'.format(dataset_name,rst)\n",
        "create_dir_if_any(res_dir)\n",
        "\n",
        "bg_train_full = BatchGen(BatchGen.TRAIN, batch_size,\n",
        "                         dataset_name, rst,prune_classes=prune,\n",
        "                         )\n",
        "\n",
        "counter = [0] * 12 + [219, 112, 38]\n",
        "prune = [counter[i] - k_shot for i in range(len(counter))]\n",
        "bg_test = BatchGen(BatchGen.TEST, batch_size, dataset_name, rst, prune_classes=[])\n",
        "\n",
        "channels = bg_train_full.dataset_x[0].shape[-1]\n",
        "\n",
        "print(\"input data loaded...\")\n",
        "\n",
        "shape = bg_train_full.dataset_x[0].shape\n",
        "\n",
        "print('img shape', shape)\n",
        "classes = bg_train_full.get_label_table()\n",
        "# Initialize statistics information\n",
        "gan_train_losses = defaultdict(list)\n",
        "gan_test_losses = defaultdict(list)\n",
        "\n",
        "img_samples = defaultdict(list)\n",
        "\n",
        "# For all possible minority classes.\n",
        "target_classes = np.array(range(len(classes)))\n",
        "\n",
        "\n",
        "print('train counters: ', bg_train_full.per_class_count)\n",
        "print('test counters: ', bg_test.per_class_count)\n",
        "\n",
        "# Train GAN to balance the data\n",
        "gan = FxGan(\n",
        "    target_classes, loss_type,\n",
        "    adam_lr=adam_lr, latent_size=latent_size,res_dir=res_dir,image_shape=shape,\n",
        "    g_lr = g_lr,\n",
        "    norm = norm,\n",
        "    resnet=resnet,\n",
        "    dataset=dataset_name,\n",
        "    attention=attention,\n",
        "    k_shot=1,\n",
        "    sampling=sampling,\n",
        "    advance_losses=advance_losses,\n",
        ")\n",
        "gan.train(bg_train_full, bg_test, epochs=gan_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFVrzSEulx-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.backup_point(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxNMusoTiPWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scatter_plot(\n",
        "    np.concatenate([bg_train_full.dataset_x, bg_test.dataset_x]),\n",
        "    np.concatenate([bg_train_full.dataset_y, bg_test.dataset_y]),\n",
        "    gan.latent_encoder, 'train','tsne')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aryKT8FNKe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "include_test = True\n",
        "\n",
        "classes = []\n",
        "for i in bg_train_full.classes:\n",
        "    classes += [i] * 100\n",
        "\n",
        "if include_test:\n",
        "    for i in bg_test.classes:\n",
        "        classes += [i] * 100\n",
        "\n",
        "\n",
        "gan.plot_cm_for_G(bg_train_full,\n",
        "                  bg_test if include_test else None,\n",
        "                  classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npRh2R5TfNcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Counter(bg_test.dataset_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWzAeGbNOi69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from data_augmentation.model import *\n",
        "x_test_u, x_sp_u, y_test_u, y_sp_u = train_test_split(bg_test.dataset_x, bg_test.dataset_y)\n",
        "# print(y_test_u.shape, y_sp_u.shape)\n",
        "# print(Counter(y_test_u), Counter(y_sp_u))\n",
        "evaluate_model_metric(gan.latent_encoder, ( x_sp_u,y_sp_u), \n",
        "                                    x_test_u, y_test_u-np.min(y_test_u) ,\n",
        "                                    k_shot=5, metric='l2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wF3CDFKzS0G",
        "colab_type": "text"
      },
      "source": [
        "Plot data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14PKWVUqdg-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test = 1\n",
        "same_img = False\n",
        "show = False\n",
        "test_size = 10\n",
        "bg = bg_train_full if not test else bg_test\n",
        "\n",
        "gan.show_samples_for_class(bg, 99 , mode = '10')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1OazBzjifeG",
        "colab_type": "text"
      },
      "source": [
        "Save generative image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeYIEM5o0rUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = gan.gen_augment_data(bg_train_full,bg_test)\n",
        "show_samples(images[:10])\n",
        "images = images *127.5+127.5\n",
        "pickle_save((images, labels), '/content/drive/My Drive/generated/multi_chest/gen_v1_{}shot.pkl'.format(k_shot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWOiDdGS5lUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_samples((images[::-1][:10] - 127.5) / 127.5 )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjz6qOv-LKuA",
        "colab_type": "text"
      },
      "source": [
        "## Tu day de kiem tra mo hinh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WpkYbu_LUyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive, output\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!rm -rf '/content/gan_project'\n",
        "!git clone https://github.com/ptran1203/gan_project\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install image-classifiers\n",
        "\n",
        "\n",
        "## for Model definition/training\n",
        "from keras.models import Model, load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import applications\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from keras.regularizers import l2\n",
        "import keras.backend as K\n",
        "from keras_contrib.applications.resnet import ResNet, basic_block\n",
        "from keras_contrib.applications.densenet import DenseNet\n",
        "import keras.applications as k_apps\n",
        "from keras.layers import (\n",
        "    Input, Dense, Reshape,\n",
        "    Flatten, Embedding, Dropout,\n",
        "    BatchNormalization, Activation,\n",
        "    Lambda,Layer, Add, Concatenate,\n",
        "    Average,GlobalAveragePooling2D,\n",
        "    MaxPooling2D, AveragePooling2D,\n",
        ")\n",
        "from keras.layers.convolutional import (\n",
        "    UpSampling2D, Convolution2D,\n",
        "    Conv2D, Conv2DTranspose\n",
        ")\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "output.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSV2MywBLWzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd gan_project"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzwfRCd4LXyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from classification_models.keras import Classifiers\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.preprocessing.image as iprocess\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import keras\n",
        "import datetime\n",
        "from triplet_loss import *\n",
        "from utils import *\n",
        "from const import *\n",
        "\n",
        "import metrics\n",
        "from visualization import *\n",
        "from data_augmentation.data_loader import load_gen, load_dataset\n",
        "from data_augmentation.model import *\n",
        "import sklearn.metrics as sk_metrics\n",
        "\n",
        "\n",
        "## Load dataset\n",
        "# load data\n",
        "np.random.seed(0)\n",
        "dataset = 'multi_chest'\n",
        "resolution = 128\n",
        "train_classes = 15\n",
        "[\n",
        "    x_train, y_train, x_val, y_val,\n",
        "    x_test, y_test , x_unseen, y_unseen\n",
        "] = load_dataset(dataset, resolution, 0, train_classes)\n",
        "\n",
        "x_train, y_train = prune(\n",
        "    x_train, y_train,\n",
        "    [1000] + [0] * 14\n",
        "    # [1000]\n",
        ")\n",
        "Counter(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMS8kyE6LZJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rst, channel = x_train.shape[2:]\n",
        "input_shape = (rst, rst, channel)\n",
        "classes = np.unique(y_train)\n",
        "num_of_classes = len(classes)\n",
        "y_train_onehot = to_categorical(y_train, num_of_classes)\n",
        "y_val_onehot = to_categorical(y_val, num_of_classes)\n",
        "feat_dims = 128\n",
        "from_scratch = False\n",
        "\n",
        "print('Total classes: ', num_of_classes)\n",
        "print('Test on {} samples'.format(len(y_test)))\n",
        "\n",
        "frozen_block = []\n",
        "all_scores = {}\n",
        "experiments = 5\n",
        "save = False\n",
        "opts = [\n",
        "    Option.gan_v1,\n",
        "    Option.bagan,\n",
        "    # Option.vgg16,\n",
        "    # Option.vgg16_st_aug,\n",
        "    # Option.gan_v1,\n",
        "]\n",
        "\n",
        "feature_extractor = 'vgg16'\n",
        "learning_rate = 1e-5 if experiments == 1 else 3e-6\n",
        "loss_weights = [1, 0.0001]\n",
        "epochs = 15\n",
        "loss_type=Losses.center\n",
        "train_model = None\n",
        "k_shots = [10,5]\n",
        "\n",
        "for opt in opts:\n",
        "    for k_shot in k_shots:\n",
        "        print(\"\\n======= Experiment {} - {} shot\".format(model_map[opt], k_shot))\n",
        "        result, train_model = run(opt, (x_val, y_val),\n",
        "                    experiments, frozen_block,\n",
        "                    feature_extractor, save, learning_rate,\n",
        "                    loss_weights, epochs, loss_type=loss_type,k_shot=k_shot)\n",
        "\n",
        "        all_scores[model_map[opt]] = result\n",
        "        send(\"experiemnts {} {} shot \\n {}\".format(model_map[opt], k_shot, json.dumps(result.tolist(), indent=4)))\n",
        "\n",
        "if loss_type == Losses.center and experiments > 1:\n",
        "    table = metrics.draw_md_table(all_scores)\n",
        "    print(table)\n",
        "    # send slack\n",
        "    send(table)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}