{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier_25RAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptran1203/fxgan/blob/master/notebooks/classifier_25RAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGRLNkVD39z9"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive, output\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!rm -rf '/content/gan_project'\n",
        "!git clone https://github.com/ptran1203/gan_project\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "\n",
        "## for Model definition/training\n",
        "from keras.models import Model, load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import applications\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from keras.regularizers import l2\n",
        "import keras.backend as K\n",
        "from keras_contrib.applications.resnet import ResNet, basic_block\n",
        "from keras_contrib.applications.densenet import DenseNet\n",
        "import keras.applications as k_apps\n",
        "from keras.layers import (\n",
        "    Input, Dense, Reshape,\n",
        "    Flatten, Embedding, Dropout,\n",
        "    BatchNormalization, Activation,\n",
        "    Lambda,Layer, Add, Concatenate,\n",
        "    Average,GlobalAveragePooling2D,\n",
        "    MaxPooling2D, AveragePooling2D,\n",
        ")\n",
        "from keras.layers.convolutional import (\n",
        "    UpSampling2D, Convolution2D,\n",
        "    Conv2D, Conv2DTranspose\n",
        ")\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "output.clear()\n",
        "%cd gan_project"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYQeQd4z4HzZ"
      },
      "source": [
        "!pip install image-classifiers\n",
        "from classification_models.keras import Classifiers\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.preprocessing.image as iprocess\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import keras\n",
        "import datetime\n",
        "from triplet_loss import *\n",
        "from utils import *\n",
        "from const import *\n",
        "\n",
        "import metrics\n",
        "# from data_augmentation.dataloader import load_gen, load_dataset\n",
        "from data_augmentation.model import *\n",
        "import sklearn.metrics as sk_metrics\n",
        "\n",
        "## Load dataset\n",
        "# load data\n",
        "np.random.seed(0)\n",
        "dataset = 'face'\n",
        "resolution = 128\n",
        "large = 0\n",
        "train_classes = 80\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmUunu2U4O0g"
      },
      "source": [
        "rst, channel = 128, 3\n",
        "input_shape = (rst, rst, channel)\n",
        "feat_dims = 128\n",
        "from_scratch = False\n",
        "\n",
        "frozen_block = []\n",
        "all_scores = {}\n",
        "experiments = 1\n",
        "save = True\n",
        "opts = [\n",
        "    Option.vgg16,\n",
        "    # Option.vgg16_st_aug,\n",
        "    # Option.gan_v2,\n",
        "    # Option.gan_v1,\n",
        "    # Option.bagan\n",
        "]\n",
        "\n",
        "feature_extractor = 'vgg16'\n",
        "learning_rate = 1e-5\n",
        "loss_weights = [1, 0.01]\n",
        "epochs = 50\n",
        "\n",
        "for opt in opts:\n",
        "    result = run(opt, experiments, frozen_block,\n",
        "                feature_extractor, save, learning_rate,\n",
        "                loss_weights, epochs, dataset='face',\n",
        "                 plot_interval=10)\n",
        "\n",
        "    all_scores[model_map[opt]] = result\n",
        "# table = metrics.draw_md_table(all_scores)\n",
        "# print(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy1VsnpxXXIe"
      },
      "source": [
        "embbeding_model = Model(\n",
        "    inputs = train_model.inputs[0],\n",
        "    outputs = train_model.get_layer('side_out').get_output_at(-1)\n",
        ")\n",
        "classifier = Model(inputs = train_model.inputs[0], outputs = train_model.get_layer('main_out').get_output_at(-1))\n",
        "# classifier = flatten_model(classifier)\n",
        "classifier.compile(optimizer='adam', metrics = ['accuracy'],  loss='categorical_crossentropy')\n",
        "scatter_plot(x_train, y_train, embbeding_model, 'train')\n",
        "scatter_plot(x_unseen, y_unseen, embbeding_model, 'val')\n",
        "scatter_plot(x_test, y_test, embbeding_model, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpPMUfelXbKQ"
      },
      "source": [
        "\n",
        "def l2_distance(a, b):\n",
        "    return np.mean(np.square(a - b))\n",
        "\n",
        "def cosine_sim(a, b):\n",
        "    return - (np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b)))\n",
        "\n",
        "def cal_sp_vectors(embbeder, supports,k_shot):\n",
        "    means = []\n",
        "    x_sp, y_sp = supports\n",
        "    classes = np.unique(y_sp)\n",
        "    # perclassid\n",
        "    per_class_ids = dict()\n",
        "    ids = np.array(range(len(x_sp)))\n",
        "    for c in classes:\n",
        "        per_class_ids[c] = ids[y_sp == c]\n",
        "\n",
        "    for c in classes:\n",
        "        imgs = x_sp[per_class_ids[c][:k_shot]]\n",
        "        # imgs = utils.triple_channels(imgs)\n",
        "        latent = embbeder.predict(imgs)\n",
        "        means.append(np.mean(latent, axis=0))\n",
        "    return np.array(means)\n",
        "    \n",
        "def classify_by_metric(embbeder, supports, images, k_shot=1,metric='l2'):\n",
        "    x_sp, y_sp = supports\n",
        "    classes = np.unique(y_sp)\n",
        "    # currently do one-shot classification\n",
        "    sp_vectors = cal_sp_vectors(embbeder, supports,k_shot)\n",
        "    vectors = embbeder.predict(triple_channels(images))\n",
        "    metric_func = l2_distance if metric == 'l2' else cosine_sim\n",
        "    similiarity = np.array([metric_func(vector, sp_vector) \\\n",
        "                        for vector in vectors \\\n",
        "                        for sp_vector in sp_vectors]).reshape(-1, len(classes))\n",
        "    pred = np.argmin(np.array(similiarity), axis=1)\n",
        "    print(pred)\n",
        "    return pred\n",
        "\n",
        "def evaluate_by_metric(embbeder, supports, images, labels, k_shot=1,metric='l2'):\n",
        "    pred = classify_by_metric(embbeder, supports,\n",
        "                              images,k_shot=k_shot, metric=metric)\n",
        "\n",
        "    print(labels)\n",
        "    acc = (pred == labels).mean()\n",
        "    return acc\n",
        "\n",
        "# x_train_aug, y_train_aug = load_gen(dataset, 1)\n",
        "# x_train_aug=triple_channels(x_train_aug)\n",
        "x_sp_u, x_test_u, y_sp_u, y_test_u = train_test_split(x, y)\n",
        "evaluate_by_metric(embbeding_model,\n",
        "                   (x_test_u, y_test_u),\n",
        "                   x_sp_u, y_sp_u,\n",
        "                   k_shot=5, metric='cosine')\n",
        "Counter(y_unseen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I7JUxZHXc4j"
      },
      "source": [
        "print(\"Test\")\n",
        "x, y = pickle_load(\"/content/drive/My Drive/GAN/dataset/{}/imgs_labels.pkl\".format(dataset))\n",
        "fname = '/content/drive/My Drive/GAN/{}/latent_encoder_{}'.format(dataset, x.shape[1])\n",
        "embbeding_model = None\n",
        "with open(fname + '.json', 'r') as f:\n",
        "    global embbeding_model\n",
        "    embbeding_model = keras.models.model_from_json(f.read())\n",
        "    embbeding_model.load_weights(fname + '.h5')\n",
        "    scatter_plot(x, y, embbeding_model, 'train', 'tsne')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}